"use strict";(self.webpackChunkdocusaurus_test=self.webpackChunkdocusaurus_test||[]).push([[2454],{3632:(e,n,r)=>{r.d(n,{A:()=>i});const i=r.p+"assets/images/plugability-0a5c422825065afd1fdca9ab69565f8a.png"},5486:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>t,contentTitle:()=>d,default:()=>a,frontMatter:()=>c,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"architecture/Component Architecture/inf-scheduler","title":"llm-d Inference Router Architecture","description":"Overview","source":"@site/docs/architecture/Component Architecture/03_inf-scheduler.md","sourceDirName":"architecture/Component Architecture","slug":"/architecture/Component Architecture/inf-scheduler","permalink":"/docs/architecture/Component Architecture/inf-scheduler","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"Inference Scheduler"},"sidebar":"structureSidebar","previous":{"title":"Inference Extension","permalink":"/docs/architecture/Component Architecture/inf-extension"},"next":{"title":"Disagg Prefill/Decode","permalink":"/docs/architecture/Component Architecture/disagg_prefill-decode"}}');var s=r(4848),l=r(8453);const c={sidebar_position:3,sidebar_label:"Inference Scheduler"},d="llm-d Inference Router Architecture",t={},o=[{value:"Overview",id:"overview",level:2},{value:"Core Goals",id:"core-goals",level:2},{value:"Architecture Design",id:"architecture-design",level:2},{value:"Pluggability",id:"pluggability",level:3},{value:"Filters, Scorers, and Scrapers",id:"filters-scorers-and-scrapers",level:2},{value:"Core Design Principles",id:"core-design-principles",level:3},{value:"Routing Flow",id:"routing-flow",level:3},{value:"Lifecycle Hooks",id:"lifecycle-hooks",level:3},{value:"Scorers &amp; Configuration",id:"scorers--configuration",level:2},{value:"Prefill / Decode Configuration",id:"prefill--decode-configuration",level:3},{value:"Prefill Scorers:",id:"prefill-scorers",level:4},{value:"Metric Scraping",id:"metric-scraping",level:2},{value:"Disaggregated Prefill/Decode (P/D)",id:"disaggregated-prefilldecode-pd",level:2},{value:"InferencePool &amp; InferenceModel Design",id:"inferencepool--inferencemodel-design",level:2},{value:"Current Assumptions",id:"current-assumptions",level:3},{value:"References",id:"references",level:2}];function h(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"llm-d-inference-router-architecture",children:"llm-d Inference Router Architecture"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"llm-d"})," is an extensible architecture designed to route inference requests efficiently across model-serving pods. A central component of this architecture is the ",(0,s.jsx)(n.strong,{children:"Inference Gateway"}),", which builds on the Kubernetes-native ",(0,s.jsx)(n.strong,{children:"Gateway API Inference Extension (GIE)"})," to enable scalable, flexible, and pluggable routing of requests."]}),"\n",(0,s.jsx)(n.p,{children:"The design enables:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Support for ",(0,s.jsx)(n.strong,{children:"multiple base models"})," and ",(0,s.jsx)(n.strong,{children:"LoRA adapters"})," within a shared cluster [Not supported in Phase1]"]}),"\n",(0,s.jsxs)(n.li,{children:["Efficient routing based on ",(0,s.jsx)(n.strong,{children:"KV cache locality"}),", ",(0,s.jsx)(n.strong,{children:"prefix"}),", ",(0,s.jsx)(n.strong,{children:"session affinity"}),", ",(0,s.jsx)(n.strong,{children:"load"}),", and ",(0,s.jsx)(n.strong,{children:"model metadata"})]}),"\n",(0,s.jsxs)(n.li,{children:["Disaggregated ",(0,s.jsx)(n.strong,{children:"Prefill/Decode (P/D)"})," execution"]}),"\n",(0,s.jsxs)(n.li,{children:["Pluggable ",(0,s.jsx)(n.strong,{children:"filters"}),", ",(0,s.jsx)(n.strong,{children:"scorers"}),", and ",(0,s.jsx)(n.strong,{children:"scrapers"})," for extensible routing"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"core-goals",children:"Core Goals"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Route inference requests to optimal pods based on:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Base model compatibility"}),"\n",(0,s.jsx)(n.li,{children:"KV cache reuse"}),"\n",(0,s.jsx)(n.li,{children:"Load balancing"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.li,{children:"Support multi-model deployments on heterogeneous hardware"}),"\n",(0,s.jsx)(n.li,{children:"Enable runtime extensibility with pluggable logic (filters, scorers, scrapers)"}),"\n",(0,s.jsx)(n.li,{children:"Community-aligned implementation using GIE and Envoy + External Processing (EPP)"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"architecture-design",children:"Architecture Design"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Inference Gateway Architecture",src:r(7697).A+"",width:"2539",height:"1575"})}),"\n",(0,s.jsx)(n.p,{children:"The inference scheduler is built on top of:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Envoy"})," as a programmable data plane"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"EPP (External Processing Plugin)"})," using ",(0,s.jsx)(n.strong,{children:"GIE"})]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"pluggability",children:"Pluggability"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Pluggability Architecture",src:r(3632).A+"",width:"2668",height:"1498"})}),"\n",(0,s.jsx)(n.p,{children:"Routing decisions are governed by dynamic components:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Filters"}),": Exclude pods based on static or dynamic criteria"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scorers"}),": Assign scores to candidate pods"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scrapers"}),": Collect pod metadata and metrics for scorers"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["These components are maintained in the ",(0,s.jsx)(n.code,{children:"llm-d-inference-scheduler"})," repository and can evolve independently."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"filters-scorers-and-scrapers",children:"Filters, Scorers, and Scrapers"}),"\n",(0,s.jsx)(n.h3,{id:"core-design-principles",children:"Core Design Principles"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Pluggability"}),": No core changes are needed to add new scorers or filters"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isolation"}),": Each component operates independently"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"routing-flow",children:"Routing Flow"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Filtering"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Pods in an ",(0,s.jsx)(n.code,{children:"InferencePool"})," go through a sequential chain of filters"]}),"\n",(0,s.jsx)(n.li,{children:"Pods may be excluded based on criteria like model compatibility, resource usage, or custom logic"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Scoring"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Filtered pods are scored using a weighted set of scorers"}),"\n",(0,s.jsx)(n.li,{children:"Scorers currently run sequentially (future: parallel execution)"}),"\n",(0,s.jsx)(n.li,{children:"Scorers access a shared datastore populated by scrapers"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Pod Selection"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The highest-scored pod is selected"}),"\n",(0,s.jsx)(n.li,{children:"If multiple pods share the same score, one is selected at random"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"lifecycle-hooks",children:"Lifecycle Hooks"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"Pre-call"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"Scoring"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"Post-choice"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.code,{children:"After-response"})}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"scorers--configuration",children:"Scorers & Configuration"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Scorer"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Env Vars"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Session-aware"}),(0,s.jsx)(n.td,{children:"Prefers pods from same session"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"ENABLE_SESSION_AWARE_SCORER"}),", ",(0,s.jsx)(n.code,{children:"SESSION_AWARE_SCORER_WEIGHT"}),", ",(0,s.jsx)(n.code,{children:"PREFILL_ENABLE_SESSION_AWARE_SCORER"}),", ",(0,s.jsx)(n.code,{children:"PREFILL_SESSION_AWARE_SCORER_WEIGHT"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Prefix-aware"}),(0,s.jsx)(n.td,{children:"Matches prompt prefix"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"ENABLE_PREFIX_AWARE_SCORER"}),", ",(0,s.jsx)(n.code,{children:"PREFIX_AWARE_SCORER_WEIGHT"}),", ",(0,s.jsx)(n.code,{children:"PREFILL_ENABLE_PREFIX_AWARE_SCORER"}),", ",(0,s.jsx)(n.code,{children:"PREFILL_PREFIX_AWARE_SCORER_WEIGHT"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"KVCache-aware"}),(0,s.jsx)(n.td,{children:"Optimizes for KV reuse"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"ENABLE_KVCACHE_AWARE_SCORER"}),", ",(0,s.jsx)(n.code,{children:"KVCACHE_INDEXER_REDIS_ADDR"}),", ",(0,s.jsx)(n.code,{children:"PREFILL_ENABLE_KVCACHE_AWARE_SCORER"}),", ",(0,s.jsx)(n.code,{children:"PREFILL_KVCACHE_INDEXER_REDIS_ADDR"}),", ",(0,s.jsx)(n.code,{children:"HF_TOKEN"}),", ",(0,s.jsx)(n.code,{children:"KVCACHE_INDEXER_REDIS_ADDR"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Load-aware"}),(0,s.jsx)(n.td,{children:"Avoids busy pods"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"ENABLE_LOAD_AWARE_SCORER"}),", ",(0,s.jsx)(n.code,{children:"LOAD_AWARE_SCORER_WEIGHT"}),", ",(0,s.jsx)(n.code,{children:"PREFILL_ENABLE_LOAD_AWARE_SCORER"}),", ",(0,s.jsx)(n.code,{children:"PREFILL_LOAD_AWARE_SCORER_WEIGHT"})]})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"prefill--decode-configuration",children:"Prefill / Decode Configuration"}),"\n",(0,s.jsx)(n.p,{children:"In case Disaggrigated Prefill is enabled, you should also define the following environment variables."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Toggle P/D mode: ",(0,s.jsx)(n.code,{children:"PD_ENABLED=true"})]}),"\n",(0,s.jsxs)(n.li,{children:["Threshold: ",(0,s.jsx)(n.code,{children:"PD_PROMPT_LEN_THRESHOLD=<value>"})]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"prefill-scorers",children:"Prefill Scorers:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"export PREFILL_ENABLE_SESSION_AWARE_SCORER=true\r\nexport PREFILL_SESSION_AWARE_SCORER_WEIGHT=1\r\nexport PREFILL_ENABLE_KVCACHE_AWARE_SCORER=true\r\nexport PREFILL_KVCACHE_AWARE_SCORER_WEIGHT=1\r\nexport PREFILL_ENABLE_LOAD_AWARE_SCORER=true\r\nexport PREFILL_LOAD_AWARE_SCORER_WEIGHT=1\r\nexport PREFILL_ENABLE_PREFIX_AWARE_SCORER=true\r\nexport PREFILL_PREFIX_AWARE_SCORER_WEIGHT=1\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"metric-scraping",children:"Metric Scraping"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Scrapers collect metrics (e.g., memory usage, active adapters)"}),"\n",(0,s.jsx)(n.li,{children:"Data is injected into the shared datastore for scorers"}),"\n",(0,s.jsx)(n.li,{children:"Scoring can rely on numerical metrics or metadata (model ID, adapter tags)"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"disaggregated-prefilldecode-pd",children:"Disaggregated Prefill/Decode (P/D)"}),"\n",(0,s.jsx)(n.p,{children:"When enabled, the router:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Selects one pod for ",(0,s.jsx)(n.strong,{children:"Prefill"})," (prompt processing)"]}),"\n",(0,s.jsxs)(n.li,{children:["Selects another pod for ",(0,s.jsx)(n.strong,{children:"Decode"})," (token generation)"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"vLLM sidecar"})," handles orchestration between Prefill and Decode stages. It allows:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Queuing"}),"\n",(0,s.jsx)(n.li,{children:"Local memory management"}),"\n",(0,s.jsx)(n.li,{children:"Experimental protocol compatibility"}),"\n"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note"}),": The detailed P/D design is available in this document: ",(0,s.jsx)(n.a,{href:"/docs/architecture/Component%20Architecture/disagg_prefill-decode",children:"Disaggregated Prefill/Decode in llm-d"})]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"inferencepool--inferencemodel-design",children:"InferencePool & InferenceModel Design"}),"\n",(0,s.jsx)(n.h3,{id:"current-assumptions",children:"Current Assumptions"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Single ",(0,s.jsx)(n.code,{children:"InferencePool"})," and single ",(0,s.jsx)(n.code,{children:"EPP"})," due to Envoy limitations"]}),"\n",(0,s.jsx)(n.li,{children:"Model-based filtering can be handled within EPP"}),"\n",(0,s.jsx)(n.li,{children:"Currently only one base model is supported"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://gateway-api-inference-extension.sigs.k8s.io/",children:"GIE Spec"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/ext_proc_filter",children:"Envoy External Processing"})}),"\n"]})]})}function a(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},7697:(e,n,r)=>{r.d(n,{A:()=>i});const i=r.p+"assets/images/architecture-e8bfa2ceb2dfc8000fb4e51598c2c672.png"},8453:(e,n,r)=>{r.d(n,{R:()=>c,x:()=>d});var i=r(6540);const s={},l=i.createContext(s);function c(e){const n=i.useContext(l);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:c(e.components),i.createElement(l.Provider,{value:n},e.children)}}}]);