"use strict";(self.webpackChunkdocusaurus_test=self.webpackChunkdocusaurus_test||[]).push([[6808],{5433:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>t,contentTitle:()=>c,default:()=>h,frontMatter:()=>d,metadata:()=>r,toc:()=>o});const r=JSON.parse('{"id":"architecture/Component Architecture/disagg_prefill-decode","title":"Disaggregated Prefill/Decode Inference Serving in llm-d","description":"Overview","source":"@site/docs/architecture/Component Architecture/04_disagg_prefill-decode.md","sourceDirName":"architecture/Component Architecture","slug":"/architecture/Component Architecture/disagg_prefill-decode","permalink":"/docs/architecture/Component Architecture/disagg_prefill-decode","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_location":4,"sidebar_label":"Disagg Prefill/Decode","sidebar_class_name":"hidden"},"sidebar":"structureSidebar","previous":{"title":"Inference Scheduler","permalink":"/docs/architecture/Component Architecture/inf-scheduler"},"next":{"title":"Routing Sidecar","permalink":"/docs/architecture/Component Architecture/routing-sidecar"}}');var s=i(4848),l=i(8453);const d={sidebar_location:4,sidebar_label:"Disagg Prefill/Decode",sidebar_class_name:"hidden"},c="Disaggregated Prefill/Decode Inference Serving in llm-d",t={},o=[{value:"Overview",id:"overview",level:2},{value:"Goals",id:"goals",level:2},{value:"Key Components",id:"key-components",level:2},{value:"Request Lifecycle",id:"request-lifecycle",level:2},{value:"Architectural Details",id:"architectural-details",level:2},{value:"Sidecar Responsibilities (Decode Only)",id:"sidecar-responsibilities-decode-only",level:3},{value:"Worker Selection Logic",id:"worker-selection-logic",level:2},{value:"vLLM and LMCache Integration",id:"vllm-and-lmcache-integration",level:2},{value:"Drawbacks &amp; Limitations",id:"drawbacks--limitations",level:2},{value:"Design Benefits",id:"design-benefits",level:2},{value:"Future Considerations",id:"future-considerations",level:2},{value:"Diagram",id:"diagram",level:2},{value:"References",id:"references",level:2}];function a(e){const n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"disaggregated-prefilldecode-inference-serving-in-llm-d",children:"Disaggregated Prefill/Decode Inference Serving in llm-d"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(n.p,{children:["This document describes the architecture and request lifecycle for enabling ",(0,s.jsx)(n.strong,{children:"disaggregated prefill and decode (P/D)"})," inference execution in the llm-d router. The architecture aims to improve flexibility, scalability, and performance by enabling separation of prefill and decode stages onto different workers."]}),"\n",(0,s.jsxs)(n.p,{children:["This evolved version removes the requirement for sidecars on the ",(0,s.jsx)(n.strong,{children:"prefill node"}),", simplifying deployment while maintaining orchestration from the ",(0,s.jsx)(n.strong,{children:"decode node"}),"."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"goals",children:"Goals"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Enable routing of prefill and decode to different pods"}),"\n",(0,s.jsx)(n.li,{children:"Maintain low latency and high throughput"}),"\n",(0,s.jsx)(n.li,{children:"Improve resource utilization by specializing pods for prefill or decode"}),"\n",(0,s.jsx)(n.li,{children:"Align with GIE-compatible architectures for potential upstreaming"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"key-components",children:"Key Components"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Component"}),(0,s.jsx)(n.th,{children:"Role"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Prefill Worker"})}),(0,s.jsx)(n.td,{children:"Handles only prefill stage using vLLM engine"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Decode Worker"})}),(0,s.jsx)(n.td,{children:"Handles decode stage and contains the sidecar for coordination"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Sidecar (Decode)"})}),(0,s.jsx)(n.td,{children:"Orchestrates communication with prefill worker and manages lifecycle"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Envoy Proxy"})}),(0,s.jsx)(n.td,{children:"Accepts OpenAI-style requests and forwards them to EPP"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"EPP"})}),(0,s.jsx)(n.td,{children:"End Point Picker, makes scheduling decisions"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"request-lifecycle",children:"Request Lifecycle"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"User Request"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Sent via OpenAI API to the Envoy Proxy"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"EPP Scheduling Decision"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["EPP evaluates:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Prompt length"}),"\n",(0,s.jsx)(n.li,{children:"KV cache hit probability"}),"\n",(0,s.jsx)(n.li,{children:"System and pod load"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Selects either:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Single node"})," path (decode handles all)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Split node"})," path (distinct prefill and decode workers)"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.li,{children:"Returns Decode Worker (always), and optionally Prefill Worker URL"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Execution"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Request lands on Decode Worker (as selected by EPP)"}),"\n",(0,s.jsxs)(n.li,{children:["Decode sidecar coordinates:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["If ",(0,s.jsx)(n.code,{children:"prefill_worker_id == nil"}),", runs both stages locally by passing request to local vllm"]}),"\n",(0,s.jsxs)(n.li,{children:["If split:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Sends prefill job to Prefill Worker with a special header ",(0,s.jsx)(n.code,{children:"do_remote_decode=true"})]}),"\n",(0,s.jsx)(n.li,{children:"Upon receiving response from Prefill Worker runs decode stage"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Response Flow"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Response flows from decode sidecar \u2192 Envoy \u2192 EPP \u2192 User"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"architectural-details",children:"Architectural Details"}),"\n",(0,s.jsx)(n.h3,{id:"sidecar-responsibilities-decode-only",children:"Sidecar Responsibilities (Decode Only)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Receives EPP metadata (decode pod, optional prefill pod)"}),"\n",(0,s.jsx)(n.li,{children:"Sends request to prefill"}),"\n",(0,s.jsx)(n.li,{children:"Waits and validates result"}),"\n",(0,s.jsx)(n.li,{children:"Launches local decode job"}),"\n",(0,s.jsx)(n.li,{children:"Sends final response"}),"\n"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Note"}),": No sidecar or coordination logic is needed on the prefill node."]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"worker-selection-logic",children:"Worker Selection Logic"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Decode Worker"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Prefer longest prefix match / KV cache utilization (depends on avaialble scorers)"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Prefill Worker"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"High prefix-cache hit rate"}),"\n",(0,s.jsx)(n.li,{children:"Low load"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Skip prefill worker"})," when:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Prefix match/kv cache hit is high"}),"\n",(0,s.jsx)(n.li,{children:"Prompt is very short"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"vllm-and-lmcache-integration",children:"vLLM and LMCache Integration"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"vLLM changes"})," (or wrapper APIs):","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"save()"}),", ",(0,s.jsx)(n.code,{children:"load()"})," APIs"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"done_sending"}),", ",(0,s.jsx)(n.code,{children:"done_receiving"})]}),"\n",(0,s.jsx)(n.li,{children:"Connector API supporting async transfer"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"drawbacks--limitations",children:"Drawbacks & Limitations"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Slight increase in TTFT for split P/D"}),"\n",(0,s.jsx)(n.li,{children:"Possibility of stranded memory on prefill crash"}),"\n",(0,s.jsx)(n.li,{children:"Need for timeout and retry logic"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"design-benefits",children:"Design Benefits"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Flexibility"}),": Enables per-request specialization and resource balancing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scalability"}),": Clean separation of concerns for easier ops and tuning"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Upstream-ready"}),": Follows GIE-compatible request handling"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Minimal Changes"}),": Only decode node includes orchestration sidecar"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"future-considerations",children:"Future Considerations"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Cache coordinate"}),"\n",(0,s.jsx)(n.li,{children:"Pre allocation of kv blocks in decode node , push cache from prefill to decode worker during calculation"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"diagram",children:"Diagram"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Disaggregated Prefill/Decode Architecture",src:i(6880).A+"",width:"1296",height:"798"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},6880:(e,n,i)=>{i.d(n,{A:()=>r});const r=i.p+"assets/images/dp_architecture-c1a2abd0813b2b0a74f0e813243ce2fc.png"},8453:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>c});var r=i(6540);const s={},l=r.createContext(s);function d(e){const n=r.useContext(l);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),r.createElement(l.Provider,{value:n},e.children)}}}]);