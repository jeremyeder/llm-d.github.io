"use strict";(self.webpackChunkdocusaurus_test=self.webpackChunkdocusaurus_test||[]).push([[594],{7829:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>d});const l=JSON.parse('{"id":"guide/Installation/quickstart","title":"Trying llm-d via the Quick Start installer","description":"This guide will walk you through the steps to install and deploy the llm-d quickstart demo on a Kubernetes cluster.","source":"@site/docs/guide/Installation/quickstart.md","sourceDirName":"guide/Installation","slug":"/guide/Installation/quickstart","permalink":"/webdocs/docs/guide/Installation/quickstart","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"guideSidebar","previous":{"title":"Prerequisites for running llm-d","permalink":"/webdocs/docs/guide/Installation/prerequisites"}}');var t=n(4848),i=n(8453);const r={sidebar_position:2},a="Trying llm-d via the Quick Start installer",o={},d=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"llm-d Installation",id:"llm-d-installation",level:2},{value:"Usage",id:"usage",level:3},{value:"Flags",id:"flags",level:3},{value:"Examples",id:"examples",level:2},{value:"Install llm-d on an Existing Kubernetes Cluster",id:"install-llm-d-on-an-existing-kubernetes-cluster",level:3},{value:"Install on OpenShift with OF installed",id:"install-on-openshift-with-of-installed",level:3},{value:"Validation",id:"validation",level:3},{value:"A simple request",id:"a-simple-request",level:4},{value:"Troubleshooting",id:"troubleshooting",level:3},{value:"Uninstall",id:"uninstall",level:3}];function c(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"trying-llm-d-via-the-quick-start-installer",children:"Trying llm-d via the Quick Start installer"})}),"\n",(0,t.jsx)(s.p,{children:"This guide will walk you through the steps to install and deploy the llm-d quickstart demo on a Kubernetes cluster."}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"What is llm-d?"})}),"\n",(0,t.jsx)(s.p,{children:"llm-d is an open source project providing distributed inferencing for GenAI runtimes on any Kubernetes cluster. Its highly performant, scalable architecture helps reduce costs through a spectrum of hardware efficiency improvements. The project prioritizes ease of deployment+use as well as SRE needs + day 2 operations associated with running large GPU clusters."}),"\n",(0,t.jsx)(s.p,{children:"It includes:"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Prefill/decode disaggregation"}),"\n",(0,t.jsx)(s.li,{children:"KV Cache distribution, offloading and storage hierarchy"}),"\n",(0,t.jsx)(s.li,{children:"AI-aware router with plug points for customizable scorers"}),"\n",(0,t.jsx)(s.li,{children:"Operational telemetry for production, prometheus/grafana"}),"\n",(0,t.jsx)(s.li,{children:"Kubernetes-based, works on OCP, minikube, and other k8s distributions"}),"\n",(0,t.jsx)(s.li,{children:"NIXL inference transfer library"}),"\n"]}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.a,{href:"/webdocs/docs/architecture/architecture",children:"For more information check out the Architecture Documentation"})}),"\n",(0,t.jsx)(s.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(s.p,{children:["Check the ",(0,t.jsx)(s.a,{href:"/webdocs/docs/guide/Installation/prerequisites",children:"prerequisites"})," for the ",(0,t.jsx)(s.a,{href:"/webdocs/docs/guide/Installation/prerequisites#compute-resources",children:"compute resources"}),", and ",(0,t.jsx)(s.a,{href:"/webdocs/docs/guide/Installation/prerequisites#software-prerequisites----client-configuration",children:"client configuration"})," required to run this demonstration."]}),"\n",(0,t.jsx)(s.h2,{id:"llm-d-installation",children:"llm-d Installation"}),"\n",(0,t.jsxs)(s.p,{children:["The llm-d-deployer contains all the helm charts necessary to deploy llm-d. To facilitate the installation of the helm charts, the ",(0,t.jsx)(s.code,{children:"llmd-installer.sh"})," script is provided. This script will populate the necessary manifests in the ",(0,t.jsx)(s.code,{children:"manifests"})," directory.\r\nAfter this, it will apply all the manifests in order to bring up the cluster."]}),"\n",(0,t.jsx)(s.p,{children:"The llmd-installer.sh script aims to simplify the installation of llm-d using the llm-d-deployer as it's main function.  It scripts as many of the steps as possible to make the installation process more streamlined.  This includes:"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"Installing the GAIE infrastructure"}),"\n",(0,t.jsx)(s.li,{children:"Creating the namespace with any special configurations"}),"\n",(0,t.jsx)(s.li,{children:"Creating the pull secret to download the images"}),"\n",(0,t.jsx)(s.li,{children:"Creating storage and downloading the model"}),"\n",(0,t.jsx)(s.li,{children:"Creating the model service CRDs"}),"\n",(0,t.jsx)(s.li,{children:"Applying the helm charts"}),"\n",(0,t.jsx)(s.li,{children:"Deploying the sample app (model service)"}),"\n"]}),"\n",(0,t.jsx)(s.p,{children:"It also supports uninstalling the llm-d infrastructure and the sample app."}),"\n",(0,t.jsxs)(s.p,{children:["Before proceeding with the installation, ensure you have completed the prerequisites and are able to issue kubectl commands to your cluster by configuring your ",(0,t.jsx)(s.code,{children:"~/.kube/config"})," file or by using the ",(0,t.jsx)(s.code,{children:"oc login"})," command."]}),"\n",(0,t.jsx)(s.h3,{id:"usage",children:"Usage"}),"\n",(0,t.jsxs)(s.p,{children:["The installer needs to be run from the ",(0,t.jsx)(s.code,{children:"llm-d-deployer/quickstart"})," directory."]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"./llmd-installer.sh [OPTIONS]\n"})}),"\n",(0,t.jsx)(s.h3,{id:"flags",children:"Flags"}),"\n",(0,t.jsxs)(s.table,{children:[(0,t.jsx)(s.thead,{children:(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.th,{children:"Flag"}),(0,t.jsx)(s.th,{children:"Description"}),(0,t.jsx)(s.th,{children:"Example"})]})}),(0,t.jsxs)(s.tbody,{children:[(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"--hf-token TOKEN"})}),(0,t.jsxs)(s.td,{children:["HuggingFace API token (or set ",(0,t.jsx)(s.code,{children:"HF_TOKEN"})," env var)"]}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:'./llmd-installer.sh --hf-token "abc123"'})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"--auth-file PATH"})}),(0,t.jsx)(s.td,{children:"Path to your registry auth file ig not in one of the two listed files in the auth section of the readme"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"./llmd-installer.sh --auth-file ~/.config/containers/auth.json"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"--storage-size SIZE"})}),(0,t.jsx)(s.td,{children:"Size of storage volume (default: 7Gi)"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"./llmd-installer.sh --storage-size 15Gi"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"--storage-class CLASS"})}),(0,t.jsx)(s.td,{children:"Storage class to use (default: efs-sc)"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"./llmd-installer.sh --storage-class ocs-storagecluster-cephfs"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"--namespace NAME"})}),(0,t.jsxs)(s.td,{children:["Kubernetes namespace to use (default: ",(0,t.jsx)(s.code,{children:"llm-d"}),")"]}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"./llmd-installer.sh --namespace foo"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"--values NAME"})}),(0,t.jsx)(s.td,{children:"Absolute path to a Helm values.yaml file (default: llm-d-deployer/charts/llm-d/values.yaml)"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"./llmd-installer.sh --values /path/to/values.yaml"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"--uninstall"})}),(0,t.jsx)(s.td,{children:"Uninstall llm-d and cleanup resources"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"./llmd-installer.sh --uninstall"})})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsxs)(s.td,{children:[(0,t.jsx)(s.code,{children:"-h"}),", ",(0,t.jsx)(s.code,{children:"--help"})]}),(0,t.jsx)(s.td,{children:"Show help and exit"}),(0,t.jsx)(s.td,{children:(0,t.jsx)(s.code,{children:"./llmd-installer.sh --help"})})]})]})]}),"\n",(0,t.jsx)(s.h2,{id:"examples",children:"Examples"}),"\n",(0,t.jsx)(s.h3,{id:"install-llm-d-on-an-existing-kubernetes-cluster",children:"Install llm-d on an Existing Kubernetes Cluster"}),"\n",(0,t.jsxs)(s.p,{children:["The storage class used for AWS ec2 is ",(0,t.jsx)(s.code,{children:"efs-sc"}),". Modify ",(0,t.jsx)(s.a,{href:"../helpers/k8s/model-storage-rwx-pvc.yaml",children:"model-storage-rwx-pvc.yaml"}),"\r\nfor a different type."]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'export HF_TOKEN="your-token"\r\n./llmd-installer.sh\n'})}),"\n",(0,t.jsx)(s.h3,{id:"install-on-openshift-with-of-installed",children:"Install on OpenShift with OF installed"}),"\n",(0,t.jsx)(s.p,{children:"Before running the installer, ensure you have logged into the cluster.  For example:"}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"oc login --token=sha256~yourtoken --server=https://api.yourcluster.com:6443\n"})}),"\n",(0,t.jsxs)(s.p,{children:["The installer will create a ReadWriteMany PVC and download the model to it, if you are using OF, you can pass in the ",(0,t.jsx)(s.code,{children:"--storage-class ocs-storagecluster-cephfs"})," flag."]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'export HF_TOKEN="your-token"\r\n./llmd-installer.sh --storage-class ocs-storagecluster-cephfs --storage-size 15Gi\n'})}),"\n",(0,t.jsx)(s.h3,{id:"validation",children:"Validation"}),"\n",(0,t.jsx)(s.h4,{id:"a-simple-request",children:"A simple request"}),"\n",(0,t.jsxs)(s.p,{children:["For GPU-enabled clusters, you can quickly verify the setup. Once both the prefill and\r\ndecode pods are running and ready, simply send a curl request to the gateway to confirm that chat\r\ncompletions are working.  You can execute the ",(0,t.jsx)(s.code,{children:"test-request.sh"})," script to test the chat completions, or run the following on your own.\r\nIf everything is working as expected, you should receive a response.  You should also see activity in the epp pod."]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'NAMESPACE=llm-d\r\nMODEL_ID=Llama-32-3B-Instruct\r\nGATEWAY_ADDRESS=$(kubectl get gateway -n ${NAMESPACE} | tail -n 1 | awk \'{print $3}\')\r\nkubectl run --rm -i curl-temp --image=curlimages/curl --restart=Never -- \\\r\n  curl -X POST \\\r\n  "http://${GATEWAY_ADDRESS}/v1/chat/completions" \\\r\n  -H \'accept: application/json\' \\\r\n  -H \'Content-Type: application/json\' \\\r\n  -d \'{\r\n    "model": "\'${MODEL_ID}\'",\r\n    "messages": [{"content": "Who are you?", "role": "user"}],\r\n    "stream": false\r\n  }\'\n'})}),"\n",(0,t.jsx)(s.p,{children:"For additional troubleshooting, you can check to see if the prefill and decode pods responding to requests."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:'NAMESPACE=llm-d\r\nMODEL_ID=Llama-3.2-3B-Instruct\r\nPOD_IP=$(kubectl get pods -n ${NAMESPACE} -o jsonpath=\'{range .items[*]}{.metadata.name}{" "}{.status.podIP}{"\\n"}{end}\' | grep decode | awk \'{print $2}\')\r\nkubectl run --rm -i curl-temp --image=curlimages/curl --restart=Never -- \\\r\n  curl -X POST \\\r\n  "http://${POD_IP}:8000/v1/chat/completions" \\\r\n  -H \'accept: application/json\' \\\r\n  -H \'Content-Type: application/json\' \\\r\n  -d \'{\r\n    "model": "\'${MODEL_ID}\'",\r\n    "messages": [{"content": "Who are you?", "role": "user"}],\r\n    "stream": false\r\n  }\'\n'})}),"\n",(0,t.jsx)(s.p,{children:"After the p/d pods are running, you can view the models being run on the GPUs on the host to verify activity."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-yaml",children:"nvidia-smi --query-gpu=index,name,utilization.gpu,utilization.memory,memory.used,memory.total --format=csv\n"})}),"\n",(0,t.jsx)(s.h3,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,t.jsx)(s.p,{children:"The various images can take some time to download depending on your connectivity. Watching events\r\nand logs of the prefill and decode pods is a good place to start."}),"\n",(0,t.jsx)(s.h3,{id:"uninstall",children:"Uninstall"}),"\n",(0,t.jsx)(s.p,{children:"This will remove llm-d resources from the cluster. This is useful, especially for test/dev if you want to\r\nmake a change, simply uninstall and then run the installer again with any changes you make."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-bash",children:"./llmd-installer.sh --uninstall\n"})})]})}function h(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>r,x:()=>a});var l=n(6540);const t={},i=l.createContext(t);function r(e){const s=l.useContext(i);return l.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),l.createElement(i.Provider,{value:s},e.children)}}}]);