"use strict";(self.webpackChunkdocusaurus_test=self.webpackChunkdocusaurus_test||[]).push([[2634],{6059:(e,s,t)=>{t.r(s),t.d(s,{default:()=>r});var a=t(797),i=t(9847),l=t(4848);function n(){return(0,l.jsx)("div",{className:"welcome welcome-viewport",children:(0,l.jsxs)("div",{className:"welcome-info",children:[(0,l.jsx)("img",{className:"llm-d-logo",width:"75%",valign:"middle",alt:"llm-d",src:"img/llm-d-logotype-and-icon.png"}),(0,l.jsx)("h2",{className:"welcome-h2",children:"llm-d: a Kubernetes-native high-performance distributed LLM inference framework"}),(0,l.jsxs)("div",{className:"button-group",children:[(0,l.jsx)("button",{className:"static-button",children:(0,l.jsx)("a",{className:"button-link",href:"docs/architecture/architecture",children:"Architecture"})}),(0,l.jsx)("button",{className:"static-button",children:(0,l.jsx)("a",{className:"button-link",href:"docs/guide/Installation/Prerequisites",children:"Installation"})}),(0,l.jsx)("button",{className:"static-button",children:(0,l.jsx)("a",{className:"button-link",href:"docs/community/contribute",children:"Community"})})]}),(0,l.jsx)("div",{className:"hidden-for-mobile",children:(0,l.jsx)("p",{children:"llm-d is a well-lit path for anyone to serve at scale, with the fastest time-to-value and competitive performance per dollar, for most models across a diverse and comprehensive set of hardware accelerators."})})]})})}function c(){return(0,l.jsx)(l.Fragment,{children:(0,l.jsx)("div",{className:"install viewport",id:"install",children:(0,l.jsxs)("div",{className:"install-info",children:[(0,l.jsx)("div",{className:"install-header",children:(0,l.jsx)("h1",{className:"install-h1",children:"Try the Quickstart Demo "})}),(0,l.jsx)("h2",{className:"install-h2",children:"It's as easy as 1...2...llm-d!"}),(0,l.jsxs)("h3",{className:"install-h3",children:[(0,l.jsx)("img",{width:"50px",valign:"middle",alt:"1. ",src:t(7494).A}),(0,l.jsx)("a",{className:"link",href:"docs/guide/installation/prerequisites#compute",children:"Check the Prerequisites"})]}),(0,l.jsxs)("h3",{className:"install-h3",children:[(0,l.jsx)("img",{width:"50px",valign:"middle",alt:"2. ",src:t(9261).A}),(0,l.jsx)("a",{className:"link",href:"docs/guide/installation/quickstart#install",children:"Run the Quickstart"})]}),(0,l.jsxs)("h3",{className:"install-h3",children:[(0,l.jsx)("img",{width:"50px",valign:"middle",alt:"3. ",src:t(9668).A}),(0,l.jsx)("a",{className:"link",href:"docs/guide/installation/quickstart#examples",children:"Explore llm-d!"})]}),(0,l.jsx)("button",{className:"static-button install-button",role:"button",href:"#",children:(0,l.jsx)("a",{className:"button-link",href:"docs/guide",children:"Complete install methods here"})})]})})})}t.p;t.p;function r(){const{siteConfig:e}=(0,a.A)();return(0,l.jsx)(i.A,{title:`Welcome to the ${e.title} website!`,description:"llm-d: a Kubernetes-native high-performance distributed LLM inference framework",children:(0,l.jsxs)("main",{children:[(0,l.jsx)(n,{}),(0,l.jsx)(c,{})]})})}},7494:(e,s,t)=>{t.d(s,{A:()=>a});const a=t.p+"assets/images/counting-01-77a463815664a562fcb55fb62bbd4eb7.png"},9261:(e,s,t)=>{t.d(s,{A:()=>a});const a=t.p+"assets/images/counting-02-f1d846c82426ad8f1aee735a329a48b7.png"},9668:(e,s,t)=>{t.d(s,{A:()=>a});const a=t.p+"assets/images/counting-03-1effeeb84ea18d016a18dc880b1a7430.png"}}]);